# Public
NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXT_PUBLIC_SUPABASE_URL=https://<PROJECT_REF>.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=<ANON_KEY>

# Server-only
SUPABASE_SERVICE_ROLE_KEY=<SERVICE_ROLE_KEY>
DATABASE_URL=postgresql://postgres:<PASSWORD>@db.<PROJECT_REF>.supabase.co:5432/postgres

# Deployment (Vercel)
VERCEL_TOKEN=
VERCEL_ORG_ID=
VERCEL_PROJECT_ID=

# AI Provider Configuration
# Primary provider: 'github-models' (recommended) or 'deepseek' (fallback)
AI_PROVIDER=github-models
AI_AUTO_SELECT=true

# GitHub Models (Primary - Recommended)
GITHUB_TOKEN=
# Or use dedicated API key:
# GITHUB_MODELS_API_KEY=
GITHUB_MODELS_BASE_URL=https://models.inference.ai.azure.com
GITHUB_MODELS_MODEL=gpt-4o

# DeepSeek (Fallback)
DEEPSEEK_API_KEY=
NSCALE_API_KEY=
DEEPSEEK_BASE_URL=
NSCALE_HEADER_NAME=X-NSCALE-API-KEY

# AI Configuration
RATE_LIMIT_PER_MINUTE=20
AI_TIMEOUT_MS=30000
AI_HEALTH_CHECK_INTERVAL_MS=300000

# Optional observability
SENTRY_DSN=

# Feature flags
FEATURE_AI_CHAT=true
